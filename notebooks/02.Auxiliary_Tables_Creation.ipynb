{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc1dd71-3d02-442e-8b04-0c97ffeb4a0e",
   "metadata": {},
   "source": [
    "### Creación de Tablas Auxiliares para el Análisis\n",
    "\n",
    "Con el objetivo de enriquecer el modelo de datos y facilitar el análisis posterior, se procede a la creación de una serie de **tablas auxiliares** derivadas de los datos existentes. Estas tablas permiten estructurar relaciones implícitas y desnormalizar información contenida en campos anidados o de tipo `JSONB`.\n",
    "\n",
    "#### Objetivos de esta fase:\n",
    "- Representar relaciones **muchos-a-muchos**, como productos por transacción.\n",
    "- Descomponer y estructurar información contenida en campos `JSONB` como `product_metadata` o `event_metadata`.\n",
    "- Mejorar la accesibilidad de los datos y optimizar consultas analíticas posteriores.\n",
    "\n",
    "Estas tablas auxiliares no forman parte del modelo relacional inicial, pero se consideran fundamentales para los análisis de comportamiento, segmentación y personalización del sistema de recomendación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc00ae-21f8-49cf-98c4-5020c5033eb3",
   "metadata": {},
   "source": [
    "## Creación de Tablas Auxiliares directamente en la Base de Datos\n",
    "\n",
    "Durante el desarrollo del sistema de análisis de comportamiento y recomendación, se ha optado por la creación de **tablas auxiliares directamente en la base de datos (PostgreSQL)** en lugar de procesarlas con dataframes.\n",
    "\n",
    "### Ventajas de esta aproximación\n",
    "\n",
    "#### 1. Eficiencia en el procesamiento\n",
    "PostgreSQL está optimizado para trabajar con grandes volúmenes de datos, permitiendo operaciones como desanidado de JSONB, agregaciones o joins complejos de forma mucho más rápida que si los datos se cargan y manipulan en memoria desde Python o herramientas de BI.\n",
    "\n",
    "#### 2. Persistencia y reutilización\n",
    "Al crear las tablas auxiliares en la base de datos, los datos derivados quedan almacenados de forma persistente y pueden ser reutilizados por múltiples procesos:\n",
    "- Dashboards en Power BI,\n",
    "- Scripts de análisis en Python,\n",
    "- Algoritmos de machine learning,\n",
    "- Exportaciones para reporting.\n",
    "\n",
    "#### 3. Optimización de consultas analíticas\n",
    "Estas tablas desnormalizadas y estructuradas facilitan consultas analíticas complejas, reduciendo el tiempo de cómputo y permitiendo una mejor planificación de índices, claves y relaciones entre entidades.\n",
    "\n",
    "#### 4. Integridad relacional\n",
    "Definir claves foráneas, restricciones y relaciones directamente en SQL permite mantener la **integridad del modelo de datos**, lo que se traduce en mayor fiabilidad en los análisis y menor probabilidad de errores.\n",
    "\n",
    "#### 5. Automatización del flujo ETL\n",
    "Incorporar estas operaciones al sistema de base de datos facilita la automatización y escalabilidad del flujo de procesamiento:\n",
    "- Se puede ejecutar mediante scripts programados (cron jobs, Airflow, etc.),\n",
    "- O integrarse en pipelines de datos empresariales.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "Crear las tablas auxiliares directamente en la base de datos proporciona una solución **más robusta, escalable y eficiente**, alineada con las necesidades analíticas del proyecto. Este enfoque también favorece la trazabilidad y reproducibilidad de los análisis, aspectos clave en entornos profesionales de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a922c2-156e-476f-80e0-ea7154c47be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine,text\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac266fc-ec35-4fd3-a748-60e1b22d3eee",
   "metadata": {},
   "source": [
    "### Conexión a la BBDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c96ae452-e373-4798-b314-30104f049bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Configuración de conexión\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")  # Default port\n",
    "\n",
    "# Crear la conexión con SQLAlchemy\n",
    "engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cde42b-31d3-4b7b-8dab-b19eee224697",
   "metadata": {},
   "source": [
    "# Creación de tabla de **'products_transaction'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a543dee8-1c3c-4ca8-85dd-a176274185b5",
   "metadata": {},
   "source": [
    "### Creación de la Tabla Auxiliar `Products_Transactions`\n",
    "\n",
    "Con el objetivo de representar de forma explícita la relación muchos-a-muchos entre productos y transacciones, se ha creado una tabla auxiliar denominada `Transaction_Products`. Esta tabla permite descomponer la información contenida en el campo `product_metadata` de la tabla `Transactions`, el cual almacena un array JSON con los productos comprados en cada sesión.\n",
    "\n",
    "#### Extracción desde JSONB\n",
    "Para ello, se utilizó la función `jsonb_array_elements()` de PostgreSQL, que permite expandir arrays de tipo `JSONB` almacenados en una columna. La consulta SQL generó una fila por cada producto incluido en el campo `product_metadata`, extrayendo los siguientes atributos:\n",
    "- `session_id`: identificador de la transacción,\n",
    "- `product_id`: identificador del producto,\n",
    "- `quantity`: cantidad comprada,\n",
    "- `item_price`: precio unitario del producto.\n",
    "\n",
    "#### Ventajas de esta aproximación\n",
    "- Mejora la normalización del modelo de datos.\n",
    "- Permite realizar análisis más detallados por producto, como frecuencia de compra o valor total generado.\n",
    "- Facilita la integración con la tabla `Products` mediante `JOIN` por `product_id`.\n",
    "\n",
    "#### Estructura de la nueva tabla\n",
    "La información extraída puede ser almacenada en una tabla llamada `Transaction_Products`, con la siguiente estructura:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS Products_Transactions (\n",
    "    session_id UUID REFERENCES Transactions(session_id),\n",
    "    product_id INT REFERENCES Products(id),\n",
    "    quantity INT,\n",
    "    item_price FLOAT,\n",
    "    PRIMARY KEY (session_id, product_id)\n",
    ");\n",
    "```\n",
    "Esta tabla servirá como base para futuras métricas como el valor total por transacción, productos más vendidos, análisis RFM y segmentación basada en comportamiento de compra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3bbdf13-b3c8-4702-add3-f1d354f9deb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabla 'Products_Transactions' creada y poblada con éxito.\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Crear conexión SQLAlchemy\n",
    "DATABASE_URL = f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Script SQL: crear tabla + insertar datos\n",
    "sql_script = \"\"\"\n",
    "-- Crear tabla si no existe\n",
    "CREATE TABLE IF NOT EXISTS Products_Transactions (\n",
    "    session_id UUID REFERENCES Transactions(session_id),\n",
    "    product_id INT REFERENCES Products(id),\n",
    "    quantity INT,\n",
    "    item_price FLOAT\n",
    ");\n",
    "\n",
    "-- Insertar datos desanidados desde product_metadata\n",
    "INSERT INTO Products_Transactions (session_id, product_id, quantity, item_price)\n",
    "SELECT \n",
    "    t.session_id,\n",
    "    (json_data->>'product_id')::INT       AS product_id,\n",
    "    (json_data->>'quantity')::INT         AS quantity,\n",
    "    (json_data->>'item_price')::FLOAT     AS item_price\n",
    "FROM (\n",
    "    SELECT session_id, jsonb_array_elements(product_metadata) AS json_data\n",
    "    FROM Transactions\n",
    ") AS t;\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar el script\n",
    "with engine.connect() as conn:\n",
    "    try:\n",
    "        with engine.begin() as conn:  # begin() gestiona transacciones automáticamente\n",
    "            conn.execute(text(sql_script))\n",
    "        print(\"✅ Tabla 'Products_Transactions' creada y poblada con éxito.\")\n",
    "    except Exception as e:\n",
    "        print(\"❌ Error al ejecutar el script:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bc58d-a271-48d8-bbd4-a570b52f231f",
   "metadata": {},
   "source": [
    "### Creación de Tablas Auxiliares a partir de `event_metadata`\n",
    "\n",
    "Con el objetivo de normalizar y estructurar la información contenida en el campo `event_metadata` de la tabla `Click_Stream`, se procede a la creación de una serie de tablas auxiliares que descomponen dicho campo según el tipo de evento.\n",
    "\n",
    "#### Motivación:\n",
    "- El campo `event_metadata` almacena información adicional en formato `JSONB`, que varía según el `event_name`.\n",
    "- Descomponer esta información permite acceder a sus atributos de forma directa, mejorar la capacidad de consulta y construir indicadores personalizados.\n",
    "\n",
    "#### Proceso general:\n",
    "1. Se analiza la estructura del campo `event_metadata` para cada tipo de evento.\n",
    "2. Se definen tablas auxiliares específicas con los atributos relevantes.\n",
    "3. Se mantiene `event_id` como clave foránea, permitiendo enlazar con el evento original.\n",
    "\n",
    "#### Objetivos:\n",
    "- Mejorar la accesibilidad y trazabilidad de los datos.\n",
    "- Permitir análisis más precisos por tipo de interacción.\n",
    "- Facilitar la construcción de visualizaciones y modelos basados en comportamiento detallado.\n",
    "\n",
    "> Esta estrategia de descomposición transforma los datos semi-estructurados en estructuras relacionales, alineadas con las buenas prácticas de modelado analítico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c310976f-3e43-4a71-b1e3-afb8ca7ad023",
   "metadata": {},
   "source": [
    "### Exploración del Campo `event_metadata`\n",
    "\n",
    "Antes de proceder a la creación de tablas auxiliares, se realizó una exploración del contenido del campo `event_metadata` de la tabla `Click_Stream`, con el objetivo de identificar las estructuras y claves más comunes asociadas a cada tipo de evento.\n",
    "\n",
    "#### Procedimiento:\n",
    "- Se extrajo una muestra representativa de 1000 registros con `event_metadata` no nulo.\n",
    "- Se agruparon los resultados por tipo de evento (`event_name`) para observar las diferencias y similitudes en la estructura de los metadatos.\n",
    "- Se amplió el ancho de visualización en el entorno de Jupyter para facilitar la lectura del contenido JSON.\n",
    "\n",
    "#### Objetivo:\n",
    "- Detectar patrones y campos recurrentes dentro de los metadatos.\n",
    "- Determinar qué atributos deben ser extraídos a tablas auxiliares específicas.\n",
    "- Sentar las bases para un modelo de datos relacional más rico y accesible.\n",
    "\n",
    "> Esta fase exploratoria es clave para transformar datos semi-estructurados en estructuras tabulares bien definidas, manteniendo la flexibilidad original del evento pero facilitando su explotación analítica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97575a57-6adb-4f29-a21a-ff2078a0cf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADD_TO_CART</td>\n",
       "      <td>{'quantity': 4, 'item_price': 313529, 'product_id': 15315}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOOKING</td>\n",
       "      <td>{'payment_status': 'Success'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEARCH</td>\n",
       "      <td>{'search_keywords': 'Dress Kondangan'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADD_TO_CART</td>\n",
       "      <td>{'quantity': 2, 'item_price': 249443, 'product_id': 6133}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADD_TO_CART</td>\n",
       "      <td>{'quantity': 1, 'item_price': 134504, 'product_id': 6721}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    event_name                                              event_metadata\n",
       "0  ADD_TO_CART  {'quantity': 4, 'item_price': 313529, 'product_id': 15315}\n",
       "1      BOOKING                               {'payment_status': 'Success'}\n",
       "2       SEARCH                      {'search_keywords': 'Dress Kondangan'}\n",
       "3  ADD_TO_CART   {'quantity': 2, 'item_price': 249443, 'product_id': 6133}\n",
       "4  ADD_TO_CART   {'quantity': 1, 'item_price': 134504, 'product_id': 6721}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel\\AppData\\Local\\Temp\\ipykernel_12832\\1161598943.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sample_by_event = df_sample.groupby(\"event_name\").apply(lambda x: x.head(3))[[\"event_metadata\"]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'promo_code': 'AZ2022', 'promo_amount': 7047}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'promo_code': 'BUYMORE', 'promo_amount': 4903}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'promo_code': 'AZ2022', 'promo_amount': 6307}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'quantity': 4, 'item_price': 313529, 'product_id': 15315}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'quantity': 2, 'item_price': 249443, 'product_id': 6133}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'quantity': 1, 'item_price': 134504, 'product_id': 6721}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'payment_status': 'Success'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'payment_status': 'Success'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'payment_status': 'Success'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'search_keywords': 'Dress Kondangan'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'search_keywords': 'Tas Wanita'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'search_keywords': 'Celana Panjang'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                event_metadata\n",
       "0               {'promo_code': 'AZ2022', 'promo_amount': 7047}\n",
       "1              {'promo_code': 'BUYMORE', 'promo_amount': 4903}\n",
       "2               {'promo_code': 'AZ2022', 'promo_amount': 6307}\n",
       "3   {'quantity': 4, 'item_price': 313529, 'product_id': 15315}\n",
       "4    {'quantity': 2, 'item_price': 249443, 'product_id': 6133}\n",
       "5    {'quantity': 1, 'item_price': 134504, 'product_id': 6721}\n",
       "6                                {'payment_status': 'Success'}\n",
       "7                                {'payment_status': 'Success'}\n",
       "8                                {'payment_status': 'Success'}\n",
       "9                       {'search_keywords': 'Dress Kondangan'}\n",
       "10                           {'search_keywords': 'Tas Wanita'}\n",
       "11                       {'search_keywords': 'Celana Panjang'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query: muestra aleatoria de eventos con metadatos\n",
    "query = \"\"\"\n",
    "SELECT event_name, event_metadata\n",
    "FROM click_stream\n",
    "WHERE event_metadata <>'{}'\n",
    "LIMIT 1000;\n",
    "\"\"\"\n",
    "\n",
    "# Leer los datos\n",
    "df_sample = pd.read_sql(query, engine)\n",
    "\n",
    "# Ampliar visibilidad en Jupyter\n",
    "pd.set_option('max_colwidth', 500)\n",
    "\n",
    "# Mostrar primeras filas\n",
    "display(df_sample.head())\n",
    "\n",
    "# Agrupar por event_name y tomar los primeros 3 ejemplos por grupo\n",
    "sample_by_event = df_sample.groupby(\"event_name\").apply(lambda x: x.head(3))[[\"event_metadata\"]]\n",
    "\n",
    "# Resetear el índice para mostrarlo bien\n",
    "sample_by_event = sample_by_event.reset_index(drop=True)\n",
    "\n",
    "# Mostrar resultado\n",
    "display(sample_by_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a2811-41bd-462b-9849-c9a380876ffe",
   "metadata": {},
   "source": [
    "### Definición de Tablas Auxiliares Derivadas de `event_metadata`\n",
    "\n",
    "A partir del análisis exploratorio del campo `event_metadata`, se identificaron varios patrones de estructura asociados a distintos tipos de eventos. Para mejorar la accesibilidad y explotabilidad de estos datos, se propone su descomposición en tablas auxiliares específicas.\n",
    "\n",
    "#### Estructuras detectadas:\n",
    "1. **Promociones**: Incluyen campos como `promo_code` y `promo_amount`.\n",
    "2. **Interacción con productos**: Información sobre `product_id`, `item_price`, y `quantity`.\n",
    "3. **Estado de pago**: Registra el resultado de una operación (`Success`, `Failed`).\n",
    "4. **Búsquedas**: Contienen el campo `search_keywords`.\n",
    "\n",
    "#### Objetivo:\n",
    "- Normalizar la información contenida en `event_metadata`.\n",
    "- Facilitar la consulta directa por tipo de información.\n",
    "- Preservar la trazabilidad de los eventos mediante la clave `event_id`.\n",
    "\n",
    "> Estas tablas actuarán como extensiones de `Click_Stream`, permitiendo un análisis más fino del comportamiento del usuario a lo largo de su navegación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ff2efe-1cfc-469a-b23d-ff862231fd20",
   "metadata": {},
   "source": [
    "### Creación de la Tabla Auxiliar `Product_Event_Metadata`\n",
    "\n",
    "Se ha creado la tabla auxiliar `Product_Event_Metadata` con el objetivo de descomponer y normalizar los detalles de producto presentes en el campo `event_metadata` de la tabla `Click_Stream`.\n",
    "\n",
    "#### Estructura de la tabla:\n",
    "- `event_id`: Clave primaria y clave foránea hacia `Click_Stream`.\n",
    "- `product_id`: Clave foránea hacia la tabla `Products`.\n",
    "- `quantity`: Cantidad del producto asociada al evento.\n",
    "- `item_price`: Precio del producto registrado en ese evento.\n",
    "\n",
    "#### Relaciones:\n",
    "- Con `ClickStream_Transactions` mediante `event_id`.\n",
    "- Con `Products` mediante `product_id`.\n",
    "\n",
    "> Esta tabla permite analizar qué productos son más clicados o visualizados, con qué frecuencia, y qué tipo de interacciones preceden una conversión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a726ba88-b06b-4b0b-a941-7b0a1d37e327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabla 'Product_Event_Metadata' creada y poblada con éxito.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SQL para crear y poblar la tabla auxiliar\n",
    "sql_script = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Product_Event_Metadata (\n",
    "    event_id UUID PRIMARY KEY REFERENCES Click_Stream(event_id),\n",
    "    product_id INT REFERENCES Products(id),\n",
    "    quantity INT,\n",
    "    item_price FLOAT\n",
    ");\n",
    "\n",
    "INSERT INTO Product_Event_Metadata (event_id, product_id, quantity, item_price)\n",
    "SELECT \n",
    "    event_id,\n",
    "    (event_metadata->>'product_id')::INT,\n",
    "    (event_metadata->>'quantity')::INT,\n",
    "    (event_metadata->>'item_price')::FLOAT\n",
    "FROM Click_Stream\n",
    "WHERE event_metadata ? 'product_id';\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar el script con gestión segura de conexión\n",
    "try:\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(sql_script))\n",
    "        print(\"✅ Tabla 'Product_Event_Metadata' creada y poblada con éxito.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error al ejecutar el script:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bbadd4-323a-40ac-92c9-62677b01ca05",
   "metadata": {},
   "source": [
    "### Creación y Población de la Tabla Auxiliar `Promo_Event_Metadata`\n",
    "\n",
    "Se ha creado y poblado la tabla auxiliar `Promo_Event_Metadata`, diseñada para almacenar los códigos promocionales y descuentos asociados a eventos de navegación.\n",
    "\n",
    "#### Estructura de la tabla:\n",
    "- `event_id`: Clave primaria y clave foránea desde `Click_Stream`.\n",
    "- `promo_code`: Código promocional aplicado.\n",
    "- `promo_amount`: Monto de descuento asociado.\n",
    "\n",
    "> Esta tabla permite analizar el uso de códigos promocionales durante la navegación, su impacto en la conversión y su distribución por canal o tipo de evento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40d279d3-c3bc-4e2f-a48f-4de5d607b17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabla 'Promo_Event_Metadata' creada y poblada con éxito.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SQL para crear y poblar la tabla Promo_Event_Metadata\n",
    "sql_script = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Promo_Event_Metadata (\n",
    "    event_id UUID PRIMARY KEY REFERENCES Click_Stream(event_id),\n",
    "    promo_code TEXT,\n",
    "    promo_amount FLOAT\n",
    ");\n",
    "\n",
    "INSERT INTO Promo_Event_Metadata (event_id, promo_code, promo_amount)\n",
    "SELECT \n",
    "    event_id,\n",
    "    event_metadata->>'promo_code',\n",
    "    (event_metadata->>'promo_amount')::FLOAT\n",
    "FROM Click_Stream\n",
    "WHERE event_metadata ? 'promo_code';\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar el script\n",
    "try:\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(sql_script))\n",
    "        print(\"✅ Tabla 'Promo_Event_Metadata' creada y poblada con éxito.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error al ejecutar el script:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c7c5a-6115-411a-9f35-f8b266412c82",
   "metadata": {},
   "source": [
    "### Creación y Población de la Tabla Auxiliar `Search_Event_Metadata`\n",
    "\n",
    "Se creó la tabla `Search_Event_Metadata` para almacenar los términos de búsqueda introducidos por los usuarios durante su navegación, extraídos del campo `event_metadata` de la tabla `Click_Stream`.\n",
    "\n",
    "#### Estructura:\n",
    "- `event_id`: Clave primaria y clave foránea hacia `Click_Stream`.\n",
    "- `search_keywords`: Término o frase buscada por el usuario.\n",
    "\n",
    "> Esta tabla es especialmente útil para analizar la intención del usuario, identificar tendencias de búsqueda y diseñar estrategias de contenido o productos basadas en intereses reales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0169b6c1-5851-458d-ab13-ba38de3b2a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabla 'Search_Event_Metadata' creada y poblada con éxito.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 43.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SQL para crear y poblar la tabla Search_Event_Metadata\n",
    "sql_script = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Search_Event_Metadata (\n",
    "    event_id UUID PRIMARY KEY REFERENCES Click_Stream(event_id),\n",
    "    search_keywords TEXT\n",
    ");\n",
    "\n",
    "INSERT INTO Search_Event_Metadata (event_id, search_keywords)\n",
    "SELECT \n",
    "    event_id,\n",
    "    event_metadata->>'search_keywords'\n",
    "FROM Click_Stream\n",
    "WHERE event_metadata ? 'search_keywords';\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar el script\n",
    "try:\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(sql_script))\n",
    "        print(\"✅ Tabla 'Search_Event_Metadata' creada y poblada con éxito.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error al ejecutar el script:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e90f48-7598-4cd8-a89f-7599f4bef538",
   "metadata": {},
   "source": [
    "### Creación y Población de la Tabla Auxiliar `Payment_Status_Metadata`\n",
    "\n",
    "Se ha creado la tabla `Payment_Status_Metadata` para almacenar los resultados de operaciones de pago registradas en los eventos de navegación. Esta información se extrae del campo `event_metadata` de la tabla `Click_Stream`.\n",
    "\n",
    "#### Estructura:\n",
    "- `event_id`: Clave primaria y clave foránea hacia `Click_Stream`.\n",
    "- `payment_status`: Estado de la transacción (ej. \"Success\", \"Failed\").\n",
    "\n",
    "> Esta tabla permite realizar análisis sobre la efectividad del proceso de pago, detectar errores recurrentes y estudiar correlaciones entre comportamiento de navegación y éxito en la transacción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "890a1302-5296-4a70-9043-f7ba2e99c3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabla 'Payment_Status_Metadata' creada y poblada con éxito.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 37.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# SQL para crear y poblar la tabla Payment_Status_Metadata\n",
    "sql_script = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Payment_Status_Metadata (\n",
    "    event_id UUID PRIMARY KEY REFERENCES Click_Stream(event_id),\n",
    "    payment_status TEXT\n",
    ");\n",
    "\n",
    "INSERT INTO Payment_Status_Metadata (event_id, payment_status)\n",
    "SELECT \n",
    "    event_id,\n",
    "    event_metadata->>'payment_status'\n",
    "FROM Click_Stream\n",
    "WHERE event_metadata ? 'payment_status';\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar el script\n",
    "try:\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(sql_script))\n",
    "        print(\"✅ Tabla 'Payment_Status_Metadata' creada y poblada con éxito.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error al ejecutar el script:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c25c1a-ff98-4d8e-807e-59665497b7f1",
   "metadata": {},
   "source": [
    "## Resumen Final: Descomposición del Campo `event_metadata`\n",
    "\n",
    "Como parte del proceso de enriquecimiento y normalización de los datos de comportamiento de usuario, se ha llevado a cabo una descomposición del campo `event_metadata` de la tabla `Click_Stream_transaction`. Este campo contenía información adicional en formato `JSONB`, cuya estructura variaba según el tipo de evento (`event_name`).\n",
    "\n",
    "### Objetivo:\n",
    "Transformar datos semi-estructurados en tablas relacionales para:\n",
    "- Mejorar la accesibilidad y trazabilidad de los datos,\n",
    "- Facilitar análisis segmentados por tipo de evento o acción,\n",
    "- Habilitar modelos avanzados de análisis del comportamiento del usuario.\n",
    "\n",
    "---\n",
    "\n",
    "### Tablas auxiliares creadas\n",
    "\n",
    "| Tabla                      | Claves extraídas de `event_metadata`                     | Claves externas |\n",
    "|---------------------------|----------------------------------------------------------|-----------------|\n",
    "| `Product_Event_Metadata`  | `product_id`, `quantity`, `item_price`                  | `event_id`, `product_id` |\n",
    "| `Promo_Event_Metadata`    | `promo_code`, `promo_amount`                            | `event_id`      |\n",
    "| `Search_Event_Metadata`   | `search_keywords`                                       | `event_id`      |\n",
    "| `Payment_Status_Metadata` | `payment_status`                                        | `event_id`      |\n",
    "\n",
    "---\n",
    "\n",
    "### Proceso aplicado:\n",
    "1. **Identificación** de claves relevantes en muestras del campo `event_metadata`.\n",
    "2. **Creación de tablas** auxiliares normalizadas, todas relacionadas con `ClickStream_Transactions` mediante `event_id`.\n",
    "\n",
    "---\n",
    "\n",
    "### Resultados:\n",
    "- Se obtuvo una estructura de datos más rica y relacionalmente sólida.\n",
    "- Se habilita la consulta directa por atributos específicos del comportamiento de usuario.\n",
    "- Se sientan las bases para análisis como funnels de conversión, rendimiento de campañas promocionales, eficiencia del pago, y tendencias de búsqueda.\n",
    "\n",
    "> Este enfoque permite integrar flexibilidad semántica con estructura relacional, facilitando tanto el análisis exploratorio como la modelización avanzada del comportamiento del consumidor.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f653c96-d80a-4a75-b6ff-4b1e589759da",
   "metadata": {},
   "source": [
    "# Estudio Estructural del Modelo de Datos\n",
    "\n",
    "Con el objetivo de realizar un análisis exhaustivo del comportamiento del consumidor y construir modelos avanzados de segmentación y recomendación, se ha diseñado una base de datos relacional enriquecida, compuesta por tablas principales y auxiliares. A continuación, se presenta un estudio detallado de la estructura actual del modelo de datos.\n",
    "\n",
    "---\n",
    "\n",
    "## Tablas Principales\n",
    "\n",
    "### `Products`\n",
    "Contiene la información del catálogo de productos disponible en el ecommerce.\n",
    "\n",
    "- **Campos:** `id`, `gender`, `masterCategory`, `subCategory`, `articleType`, `baseColour`, `season`, `year`, `usage`, `productDisplayName`\n",
    "- **Relaciones:**\n",
    "  - Se vincula con `Products_Transactions` y `Product_Event_Metadata` mediante `product_id`.\n",
    "\n",
    "---\n",
    "\n",
    "### `Customers`\n",
    "Almacena los datos de los usuarios registrados en la plataforma.\n",
    "\n",
    "- **Campos:** `customer_id`, `first_name`, `last_name`, `email`, `gender`, `birthdate`, etc.\n",
    "- **Relaciones:**\n",
    "  - Se vincula con `Transactions` mediante `customer_id`.\n",
    "\n",
    "---\n",
    "\n",
    "### `Transactions`\n",
    "Registra las sesiones de compra realizadas por los usuarios.\n",
    "\n",
    "- **Campos:** `session_id`, `created_at`, `customer_id`, `booking_id`, `product_metadata` (JSONB)\n",
    "- **Relaciones:**\n",
    "  - Se vincula con `Customers` mediante `customer_id`.\n",
    "  - Se descompone en `Products_Transactions` mediante el campo `product_metadata`.\n",
    "\n",
    "---\n",
    "\n",
    "### `Click_Stream`\n",
    "Contiene el log de eventos de navegación (clicks, búsquedas, promociones, etc.).\n",
    "\n",
    "- **Campos:** `event_id`, `session_id`, `event_name`, `event_time`, `traffic_source`, `event_metadata` (JSONB)\n",
    "- **Relaciones:**\n",
    "  - Se vincula con todas las tablas auxiliares de eventos mediante `event_id`.\n",
    "\n",
    "---\n",
    "\n",
    "## Tablas Auxiliares\n",
    "\n",
    "### `Products_Transactions`\n",
    "Representa la relación muchos-a-muchos entre productos y transacciones.\n",
    "\n",
    "- **Campos:** `session_id`, `product_id`, `quantity`, `item_price`\n",
    "- **Origen:** Desanidado desde `Transactions.product_metadata`\n",
    "- **Relaciones:** une `Products` con `Transactions`.\n",
    "\n",
    "---\n",
    "\n",
    "### `Product_Event_Metadata`\n",
    "Descompone eventos de producto (vista, clic, carrito) desde el campo `event_metadata`.\n",
    "\n",
    "- **Campos:** `event_id`, `product_id`, `quantity`, `item_price`\n",
    "- **Origen:** `Click_Stream.event_metadata`\n",
    "- **Relaciones:** une `Products` con `Click_Stream`.\n",
    "\n",
    "---\n",
    "\n",
    "### `Promo_Event_Metadata`\n",
    "Registra promociones aplicadas durante eventos de navegación o compra.\n",
    "\n",
    "- **Campos:** `event_id`, `promo_code`, `promo_amount`\n",
    "- **Origen:** `Click_Stream.event_metadata`\n",
    "\n",
    "---\n",
    "\n",
    "### `Search_Event_Metadata`\n",
    "Contiene los términos de búsqueda introducidos por el usuario.\n",
    "\n",
    "- **Campos:** `event_id`, `search_keywords`\n",
    "- **Origen:** `Click_Stream.event_metadata`\n",
    "\n",
    "---\n",
    "\n",
    "### `Payment_Status_Metadata`\n",
    "Almacena el estado del pago asociado a ciertos eventos.\n",
    "\n",
    "- **Campos:** `event_id`, `payment_status`\n",
    "- **Origen:** `Click_Stream.event_metadata`\n",
    "\n",
    "---\n",
    "\n",
    "## Relaciones entre Tablas (Resumen)\n",
    "\n",
    "```text\n",
    "Customers ─────┐\n",
    "               └──▶ Transactions ───▶ Products_Transactions ◀── Products\n",
    "Click_Stream ──┬──▶ Product_Event_Metadata ◀── Products\n",
    "               ├──▶ Promo_Event_Metadata\n",
    "               ├──▶ Search_Event_Metadata\n",
    "               └──▶ Payment_Status_Metadata\n",
    "```\n",
    "### **Conclusión**\n",
    "Esta arquitectura relacional permite un análisis integral del comportamiento del consumidor, facilitando:\n",
    "\n",
    "- Estudios de patrones de compra y navegación.\n",
    "\n",
    "- Segmentación basada en RFM, actividad o intereses.\n",
    "\n",
    "- Recomendación de productos personalizada.\n",
    "\n",
    "- Medición de efectividad de campañas y promociones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a945cd2-6387-441e-9c9e-56f4f97b8c00",
   "metadata": {},
   "source": [
    "## Enriquecimiento de la Tabla `Product_Event_Metadata` con Indicador de Compra\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "El propósito de esta operación es **identificar si un producto visualizado durante una sesión fue finalmente comprado**, permitiendo así diferenciar entre simples interacciones y conversiones reales. Esta información es clave para calcular:\n",
    "\n",
    "- La tasa de conversión por producto o categoría.\n",
    "- El abandono de productos tras visualización o añadido al carrito.\n",
    "- Métricas de eficacia de recomendaciones o promociones.\n",
    "\n",
    "### Justificación\n",
    "\n",
    "La tabla `Product_Event_Metadata` captura interacciones con productos (vistas, clics, etc.), pero no distingue si dichas interacciones terminaron en compra. En cambio, la tabla `Products_Transactions` contiene los productos comprados efectivamente por sesión.\n",
    "\n",
    "Al cruzar ambos conjuntos de datos (`session_id`, `product_id`), se puede enriquecer `Product_Event_Metadata` con un campo booleano `was_purchased`, que indica si ese producto fue adquirido durante la misma sesión donde ocurrió el evento.\n",
    "\n",
    "Este nuevo campo habilita análisis más profundos de comportamiento y permitirá construir mejores modelos de recomendación, segmentación o embudo de conversión.\n",
    "\n",
    "### Proceso\n",
    "\n",
    "1. Añadir la columna `was_purchased` a la tabla `Product_Event_Metadata`.\n",
    "2. Actualizar su valor a `TRUE` si existe una coincidencia con la tabla `Products_Transactions`.\n",
    "3. Tener en cuenta todos los campos, el mismo producto puede estar en la tabla `Product_Event_Metadata` pero con otro precio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b4b1e81-66d5-4dec-9cbb-a4b5c156063d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Campo 'was_purchased' añadido y actualizado con éxito en Product_Event_Metadata.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 53.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Script SQL\n",
    "sql_script = \"\"\"\n",
    "-- Añadir columna si no existe\n",
    "DO $$\n",
    "BEGIN\n",
    "    IF NOT EXISTS (\n",
    "        SELECT 1\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_name='product_event_metadata' AND column_name='was_purchased'\n",
    "    ) THEN\n",
    "        ALTER TABLE Product_Event_Metadata ADD COLUMN was_purchased BOOLEAN DEFAULT FALSE;\n",
    "    END IF;\n",
    "END$$;\n",
    "\n",
    "-- Actualizar valores a TRUE si el producto fue comprado en la misma sesión\n",
    "UPDATE Product_Event_Metadata\n",
    "SET was_purchased = TRUE\n",
    "FROM Click_Stream cs\n",
    "JOIN Products_Transactions pt\n",
    "  ON cs.session_id = pt.session_id\n",
    "WHERE Product_Event_Metadata.event_id = cs.event_id\n",
    "  AND Product_Event_Metadata.product_id = pt.product_id\n",
    "  AND Product_Event_Metadata.quantity = pt.quantity\n",
    "  AND Product_Event_Metadata.item_price = pt.item_price;\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar el script\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(sql_script))\n",
    "    print(\"✅ Campo 'was_purchased' añadido y actualizado con éxito en Product_Event_Metadata.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea6729-c9c4-4cb7-825c-ce6364d692af",
   "metadata": {},
   "source": [
    "# Enriquecimiento de la Tabla `Products` con Imágenes\n",
    "\n",
    "Para mejorar la calidad de los datos y enriquecer el análisis visual en futuras etapas del proyecto, se ha decidido incorporar imágenes representativas de cada producto en la tabla `Products`.\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo:\n",
    "- Realizar un scraping de imágenes desde motores de búsqueda (**Bing**, **Google** y **Yandex**) utilizando el nombre del producto (`productDisplayName`) como query.\n",
    "- Almacenar la URL de la imagen más relevante directamente en la tabla, en un campo adicional llamado `image_url`.\n",
    "\n",
    "---\n",
    "\n",
    "## Proceso:\n",
    "### **Ampliación de la Tabla:**\n",
    "   - Se añade un campo `image_url` en la tabla `Products` para almacenar la referencia de la imagen.\n",
    "\n",
    "### **Scraping de Imágenes:**\n",
    "   - Usando técnicas de scraping, se buscan imágenes relacionadas con el producto:\n",
    "     - **Bing**, **Google** y **Yandex** se utilizan como fuentes.\n",
    "     - En caso de no encontrar una imagen, se asigna una imagen genérica por defecto.\n",
    "\n",
    "### **Actualización de la Tabla:**\n",
    "   - Las URLs obtenidas se insertan en el campo `image_url` para su futura visualización y análisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8482603d-cece-4a13-b6c5-bd0ad6f8fe70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Columna 'image_url' añadida exitosamente en la tabla 'Products'.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 203 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Script SQL para añadir el campo image_url\n",
    "sql_script = \"\"\"\n",
    "ALTER TABLE Products ADD COLUMN IF NOT EXISTS image_url TEXT;\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar el script\n",
    "try:\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(sql_script))\n",
    "    print(\"✅ Columna 'image_url' añadida exitosamente en la tabla 'Products'.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al añadir la columna 'image_url': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce96f65-f402-4b59-8f1e-4b9f76b19584",
   "metadata": {},
   "source": [
    "# Scraping de Imágenes para Enriquecer la Tabla `Products`\n",
    "\n",
    "Para enriquecer visualmente los datos de nuestra tabla `Products`, hemos implementado un proceso de **scraping de imágenes** desde los motores de búsqueda más populares: **Bing**, **Google** y **Yandex**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Objetivo:**\n",
    "- Obtener imágenes representativas para cada producto de la tabla `Products`.\n",
    "- Poblar el campo `image_url` con la URL de la imagen más relevante encontrada.\n",
    "\n",
    "---\n",
    "\n",
    "## **Motores de Búsqueda Utilizados:**\n",
    "1. **Bing Images:**  \n",
    "   - Se realiza una búsqueda directa a través de peticiones HTTP y se parsea el HTML para extraer la URL de la imagen más relevante.\n",
    "\n",
    "2. **Google Images:**  \n",
    "   - Usamos Selenium en modo *headless* para interactuar con la búsqueda de imágenes y extraer la primera URL disponible.\n",
    "\n",
    "3. **Yandex Images:**  \n",
    "   - Se ejecuta una búsqueda adicional en Yandex para maximizar las posibilidades de encontrar una imagen si Bing y Google fallan.\n",
    "\n",
    "---\n",
    "\n",
    "## **Proceso de Búsqueda:**\n",
    "1. Se intenta primero en **Bing**.\n",
    "2. Si no se encuentra una imagen, se pasa a **Google**.\n",
    "3. Si Google tampoco devuelve una URL válida, se realiza una búsqueda en **Yandex**.\n",
    "4. En caso de que los tres motores de búsqueda fallen, se asigna una **imagen genérica** por defecto.\n",
    "\n",
    "---\n",
    "\n",
    "## **Próximo Paso:**\n",
    "El siguiente paso será recorrer los productos almacenados en la base de datos, ejecutar el scraping para cada uno de ellos y actualizar el valor en el campo `image_url` dentro de la tabla `Products`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d08d43-8506-4355-9b18-187b5270f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ==== Configuración general ====\n",
    "GENERIC_IMAGE_URL = \"https://upload.wikimedia.org/wikipedia/commons/1/14/No_Image_Available.jpg\"  # <-- Pon tu imagen genérica aquí\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# ==== Configurar Selenium ====\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# ==== Funciones de búsqueda ====\n",
    "def search_image_bing(query):\n",
    "    try:\n",
    "        query = query.replace(' ', '+')\n",
    "        url = f\"https://www.bing.com/images/search?q={query}&form=HDRSC2\"\n",
    "        res = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        if res.status_code != 200:\n",
    "            return None\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        image_elements = soup.find_all('a', class_='iusc')\n",
    "        if not image_elements:\n",
    "            return None\n",
    "        first_image_json = image_elements[0].get('m')\n",
    "        image_metadata = json.loads(first_image_json)\n",
    "        return image_metadata.get('murl')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def search_image_google(query):\n",
    "    try:\n",
    "        driver.get(f\"https://www.google.com/search?q={query}&tbm=isch\")\n",
    "        time.sleep(2)\n",
    "        images = driver.find_elements(By.TAG_NAME, \"img\")\n",
    "        for img in images:\n",
    "            src = img.get_attribute(\"data-src\") or img.get_attribute(\"src\")\n",
    "            if src and src.startswith('https://encrypted-tbn0.gstatic.com/'):\n",
    "                return src\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def search_image_yandex(query):\n",
    "    try:\n",
    "        driver.get(f\"https://yandex.com/images/search?text={query}\")\n",
    "        time.sleep(2)\n",
    "        images = driver.find_elements(By.TAG_NAME, \"img\")\n",
    "        for img in images:\n",
    "            src = img.get_attribute(\"src\")\n",
    "            if src and src.startswith('https://') and 'nimages' not in src:\n",
    "                return src\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def find_best_image(query):\n",
    "    print(f\"Searching Bing for: {query}\")\n",
    "    img = search_image_bing(query)\n",
    "    if img:\n",
    "        print(\"✅ Found in Bing\")\n",
    "        return img\n",
    "\n",
    "    print(f\"Not found in Bing. Trying Google...\")\n",
    "    img = search_image_google(query)\n",
    "    if img:\n",
    "        print(\"✅ Found in Google\")\n",
    "        return img\n",
    "\n",
    "    print(f\"Not found in Google. Trying Yandex...\")\n",
    "    img = search_image_yandex(query)\n",
    "    if img:\n",
    "        print(\"✅ Found in Yandex\")\n",
    "        return img\n",
    "\n",
    "    print(\"❌ No image found. Assigning generic image.\")\n",
    "    return GENERIC_IMAGE_URL\n",
    "\n",
    "# ==== Parámetros de trabajo ====\n",
    "# ==== Consulta SQL para extraer productos ====\n",
    "query = \"SELECT id, productdisplayname FROM Products\"\n",
    "\n",
    "output_csv = 'final_product_images.csv'\n",
    "\n",
    "# ==== Cargar productos ====\n",
    "df = pd.read_sql(query, engine)\n",
    "df = df.rename(columns={'productdisplayname': 'productDisplayName'})\n",
    "products = df[['id', 'productDisplayName']].dropna()\n",
    "\n",
    "# ==== Cargar progreso previo si existe ====\n",
    "if os.path.exists(output_csv):\n",
    "    done = pd.read_csv(output_csv)\n",
    "    done_ids = set(done['id'].astype(str))\n",
    "    print(f\"Resuming. Already processed {len(done_ids)} products.\")\n",
    "else:\n",
    "    done_ids = set()\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\", \"ProductDisplayName\", \"ImageURL\"])\n",
    "    print(\"Starting new file.\")\n",
    "\n",
    "# ==== Procesar productos ====\n",
    "with open(output_csv, mode='a', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    processed_count = 0\n",
    "\n",
    "    for idx, row in enumerate(products.itertuples(index=False), 1):\n",
    "        product_id = str(row.id)\n",
    "        desc = row.productDisplayName\n",
    "\n",
    "        if product_id in done_ids:\n",
    "            continue  # Ya procesado\n",
    "\n",
    "        try:\n",
    "            print(f\"\\n[{idx}] Searching for: {desc}\")\n",
    "            image_url = find_best_image(desc)\n",
    "            writer.writerow([product_id, desc, image_url])\n",
    "            f.flush()\n",
    "            \n",
    "            processed_count += 1\n",
    "\n",
    "            # Simular comportamiento humano\n",
    "            sleep_time = random.uniform(2, 5)\n",
    "            print(f\"⏳ Waiting {sleep_time:.2f} seconds before next search...\")\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "            # Cada 20-30 productos, hacer una pausa larga\n",
    "            if processed_count % random.randint(20, 30) == 0:\n",
    "                long_sleep = random.uniform(60, 90)\n",
    "                print(f\"💤 Taking a long break of {long_sleep:.2f} seconds...\")\n",
    "                time.sleep(long_sleep)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {desc}: {e}\")\n",
    "            writer.writerow([product_id, desc, GENERIC_IMAGE_URL])\n",
    "            f.flush()\n",
    "            continue\n",
    "\n",
    "# ==== Cerrar Selenium ====\n",
    "driver.quit()\n",
    "\n",
    "print(f\"\\n✅ ¡Todos los productos procesados! Resultado guardado en {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b59d9-f8a0-43c5-9893-f2aa4aa4d986",
   "metadata": {},
   "source": [
    "# Justificación del uso de un CSV para almacenar los resultados del Scraping\n",
    "\n",
    "El proceso de scraping de imágenes para los productos implica realizar múltiples peticiones HTTP a motores de búsqueda (Bing, Google, Yandex). Esto puede implicar tiempos de espera elevados, errores intermitentes en las conexiones y bloqueos temporales por parte de los servidores. Por este motivo, la decisión de almacenar los resultados en un archivo CSV se justifica por las siguientes razones:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Resiliencia ante errores de red**\n",
    "El scraping es un proceso propenso a fallos por:\n",
    "- Errores de conexión (timeouts, denegaciones del servidor, etc.).\n",
    "- Cambios en la estructura HTML de las páginas objetivo.\n",
    "- Bloqueos temporales por parte de los servidores al detectar múltiples peticiones en poco tiempo.\n",
    "\n",
    "Al guardar los resultados en un CSV de manera incremental, es posible **pausar y reanudar el proceso** en caso de fallos sin perder el progreso, ya que solo se reintentan los productos que no están en el archivo.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Evitar transacciones masivas en la base de datos**\n",
    "Realizar múltiples inserciones en la base de datos mientras se ejecuta el scraping podría:\n",
    "- Aumentar la latencia en la base de datos.\n",
    "- Generar locks (bloqueos) en las tablas afectadas.\n",
    "- Causar inconsistencias en caso de una caída inesperada del proceso.\n",
    "\n",
    "El CSV permite un enfoque **batch** (por lotes) para la inserción de datos. Una vez finalizado el scraping, se puede procesar el archivo y hacer un único `BULK INSERT`, optimizando el rendimiento y reduciendo el riesgo de errores transaccionales.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Facilidad de revisión y validación**\n",
    "El CSV es un formato **fácilmente auditable**:\n",
    "- Podemos revisar manualmente las URLs obtenidas.\n",
    "- Es sencillo identificar imágenes faltantes o URLs erróneas.\n",
    "- En caso de problemas, se puede modificar el CSV antes de subir los datos finales a la base de datos.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Integración con procesos ETL**\n",
    "Este enfoque facilita la integración en un flujo ETL:\n",
    "1. **Extract:** Scraping de las imágenes.\n",
    "2. **Transform:** Validación y limpieza de URLs en el CSV.\n",
    "3. **Load:** Carga optimizada en la base de datos.\n",
    "\n",
    "---\n",
    "\n",
    "### **Flujo propuesto:**\n",
    "1️ Scraping → 2️ Almacenamiento en CSV → 3️ Validación → 4️ Carga en la base de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e448381-3a70-4d22-959f-e88f71ea85d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Las URLs de las imágenes se han actualizado correctamente en la tabla Products.\n",
      "CPU times: total: 5.83 s\n",
      "Wall time: 8.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ==== Leer el CSV generado ====\n",
    "csv_path = 'final_product_images.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df.rename(columns={'ImageURL': 'image_url'})\n",
    "\n",
    "# ==== Actualización en bloques con COMMIT explícito ====\n",
    "update_query = text(\"\"\"\n",
    "    UPDATE Products\n",
    "    SET image_url = :image_url\n",
    "    WHERE id = :id\n",
    "\"\"\")\n",
    "\n",
    "# Dividir el DataFrame en bloques de 1000\n",
    "def chunk_df(dataframe, chunk_size=1000):\n",
    "    \"\"\"Divide un DataFrame en bloques más pequeños\"\"\"\n",
    "    for i in range(0, len(dataframe), chunk_size):\n",
    "        yield dataframe.iloc[i:i + chunk_size]\n",
    "\n",
    "# Conexión directa para múltiples actualizaciones\n",
    "with engine.connect() as connection:\n",
    "    for chunk in chunk_df(df):\n",
    "        trans = connection.begin()  # Iniciar transacción\n",
    "        try:\n",
    "            for _, row in chunk.iterrows():\n",
    "                connection.execute(update_query, {\n",
    "                    \"image_url\": row['image_url'],\n",
    "                    \"id\": int(row['id'])\n",
    "                })\n",
    "            trans.commit()  # Realizar el commit explícito\n",
    "        \n",
    "        except Exception as e:\n",
    "            trans.rollback()  # Revertir si hay un error\n",
    "            print(f\"❌ Error en la transacción: {e}\")\n",
    "                \n",
    "print(\"\\n✅ Las URLs de las imágenes se han actualizado correctamente en la tabla Products.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d48113-c66e-4e8e-8c05-6a881eb87e6c",
   "metadata": {},
   "source": [
    "## **Conclusión**\n",
    "El scraping de imágenes permitió enriquecer la base de datos de productos con URLs de imágenes de alta calidad, optimizando la presentación visual del catálogo. Gracias al uso del CSV, el proceso se mantuvo resiliente y fácilmente auditable, facilitando una actualización limpia y efectiva en PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb120131-0d89-4b0d-9f0a-54d105451af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
